---
title: "Stance on Artificial Intelligence"
author: "Rayne Aurit"
date: "2026-01-15"
categories: [blog]
draft: true
---

This post will serve as the starting point for my opinion on Artificial Intelligence. This opinion will be guaranteed to change over time as the technology becomes more sophisticated and more people become aware of its uses. I am eager to learn how it will change as I continue to work with Artificial Intelligence as someone who trains machine learning models and helps design AI agent frameworks.

# Introduction

As a student, and more specifically, a student who has experience with multiple forms of artificial intelligence, it is important to understand the advantages and disadvantages of artificial intelligence and its impact on the world around us and ourselves. Artificial Intelligence, much like most modern technological advancements, is a tool whose responsibility of proper usage currently belongs on the user only. To define Artificial Intelligence, it is the ability of a computer processes through an algorithm to make a decision. Most language surrounding Artificial Intelligence, or AI, is in reference to Large Language Models such as ChatGPT, Copilot, or Gemini. My stance will include other forms such as self-driving vehicles, image-generating AI in specific contexts, and bot accounts on the internet.

# Issues with Artificial Intelligence

Across the United States, in this past year, there has been a concerted effort to inhibit regulation of the growth of artificial intelligence with praise and support for how fast this technology is growing in comparison to the lack of legal efforts to prevent some of the harmful effects.

## Google and Data Centers

Google's data center went live this past year after a few years of development alongside interstate I-80 and 56th street. I am curious how Lincoln residents will feel the effects of the data center in these coming years in areas such as water quality and the cost of electricity. As a freshman, the topic of the local data center came up in discussion in my science literacy course underneath the College of Agriculture and Natural Resources. The unit that we were working on the time was water conservation after previously discussing plastic pollution. We were asked a question on if anybody knew if the data center was still being built as the site looked dormant for a long period of time, and the answer was yes. Originally, I felt proud of being the one to be able to answer the question and was aware about the development, though extremely naive and unaware of the impact of data centers in other areas of the country. I recalled Google as a great company with wonderful work experience. Those who were hired by Google were the best of the best and their facilities looked like adult playgrounds when images of them were introduced to me in middle school.

Since then, they have notably taken off language in their corporate code of conduct. "Do no evil" was replaced with "Do the right thing." It is a small, but noticeable semantic difference. While right and wrong is ambiguous in many cases, the notion of doing "no evil" brings about the mindset of avoiding harm at any costs. Doing "the right thing" may allow Google to weigh the costs and benefits of certain actions. If an action does "evil" but is arguably for the greater good and is a "right thing," then it is an action that is justified within the code of conduct, allowing for "evils" to escape the same amount of scrutiny as before.

## OpenAI and RAM, an Aside

Last summer, I got a new gaming laptop. My previous one had ran nearly completely out of storage, and it was one that I got at the beginning of Covid-19 pandemic with the intent that it was to be used for homework only. I got it before knowing that I was going to be a computer science student that would need to download and work with many different languages and their respective IDE's. I had to rent a laptop from the university every week at the end of my sophomore year because I did not have enough space to download the extension to work with the raspberry pi's at the end of the semester.

Leading to now, I bought an HP Victus gaming laptop the summer of 2025 for around \$500 during the summer sale. It came with only 8GB of RAM but the modular capability for more RAM to be installed easily. Back then, I could have gotten 32GB of RAM installed for only a hundred dollars. In September, OpenAI purchased 40% of NVIDIA's stock of RAM to be used in data centers, causing surges in RAM prices for the average consumer of up to 500%. Half of what I paid for the laptop could be spent on getting a RAM upgrade. A similar trend was seen with graphic cards with the past few years as well.

## Grok, A Case Study in "Wokeness"

Grok is the AI assistant built into the social media platform X, formerly known as Twitter. It is the most well-known of the LLMs to display the issues of not having regulation on artificial intelligence. In early July of 2025, Grok's responses changed from being factual and unbiased to literally calling itself "MechaHitler" as the goal was to decrease the "wokeness" of its responses.

Elon Musk, the CEO of X, had reportedly said earlier "We have improved @Grok significantly."[^1]

[^1]: The source for this information and following quotes can be found at <https://www.npr.org/2025/07/09/nx-s1-5462609/grok-elon-musk-antisemitic-racist-content>

I am not sure what measure of improvement is evaluated when he says "improved," but it certain increased in antisemetic, hateful statements, of which some users got the LLM to state that there was a need for a second Holocaust and that Adolf Hitler was justified in his actions. This result was from a change in the initial prompts for the LLM. Having worked with LLMs in creating an AI agent framework and running models locally, the system prompts before any person starts to interact with the LLM is deeply important. Studying prompt engineering and having knowledge of an LLMs context window and memory capabilities in terms of how many parameters were used in creating the model directly contributes to the behavior of the LLM, including its reliability. The specific change with Grok was to change the wording in its system prompt to include: "not shy away from making claims which are politically incorrect, as long as they are well substantiated...."

To define political correctness in this case, it is often negatively associated with being "woke," which is to be aware of the social biases and systemic inequalities towards certain groups of people whether it is due to their race, gender, or sexual orientation. It usually is said in reference of people who are more strict about the specific terms they use and their social openness to other groups of people. Someone would be called "woke" for including their pronouns in their bio or on their name tag or calling out people who misuse hateful terms. As being politically correct or woke- I am treating these words as interchangeable- was changed in the system prompt, it would make sense that Grok's interpretation of it to be the opposite of aware of social biases, which is to further the social biases.

## Grok, A Case Study in Deepfakes

Within the past few weeks, X has had another instance where Grok, and by proxy the entire social media platform, has become unsafe to the typical user. The issue lies once again with system prompts, but the effect was more demonstrated in images rather than hateful rhetoric.

Certain users found that when prompting Grok, there were less regulation on the image generation side of the AI assistant. Explicit images were now allowed to be generated without warning, resulting in some accounts going to real people's normal posts and prompting Grok to take their clothes off. Much CSAM (Child Sexual Abuse Materials) were generated, the update notably targeting women and children much more negatively than men.

This problem exists across all forms of generative AI. People's likeness and image can be used to create realistic versions doing inappropriate actions that they would never do themselves in real life, and often without any knowledge or permission. Putting someone's likeness on someone else's body is known as a deepfake. As generative AI becomes more sophisticated, it becomes harder to tell deepfaked content from real content. With malicious uses of deepfakes such as the one seen by Grok, the consequences are heavily mentally and socially damaging.

## The Art of... Art

Though I am a student double majoring in fields that heavily use numbers and computer applications, I do spend a lot of my time creating art, reading books, and writing stories. 

## Is This a Recession Indicator?

I commonly see this phrase online, and even more I see the "enshittification" of the internet and the world around us. Everything is a subscription now instead of paying for these once. Even worse, what you pay for isn't owned by you.

# Benefits of Artificial Intelligence

## Doing the Mundane

In a more positive swing, I do believe that there are beneficial uses of artificial intelligence. For Large Language Models, they can be used to quicken mundane tasks that would otherwise not require much thinking. In Design Studio, my team and I are creating an AI agent framework that will hasten the speed of manually inputting insurance information using computer vision. The downside of this product is that it will inevitably replace human work, and therefore potentially contribute to job loss as the technology becomes more advanced and accurate.

This is the inherent side effect of most technological advancements. Instead of drying our clothes on a rack where they are hung outside to dry, we invented the dryer. Instead of needing to operate maps and the ever-changing cities and towns we live in, we invented GPS services that live on our phones where all we have to do is type in a destination and we will get a turn-by-turn on how to get there. Instead of doing mathematics by hand, we invented the calculator to crunch numbers for us. Instead of having to fill in document entries, dragging and clicking the mouse over and over, we can use artificial intelligence to read in data and to populate fields for us. Instead of losing the art of real-world navigation, we save our hands minimally from getting carpal tunnel.

## Machine Learning

The middle ground of computer science and statistics falls right into either programming languages such as R or, more specifically, using machine learning algorithms to analyze data and find hidden patterns. The second semester of my sophomore year, I took the course "Intro to Machine Learning" underneath the school of computing. This semester I am taking "Statistical Learning" underneath the statistics department. I imagine that the content will be the same but the methods and details discussed will be different. The Machine Learning class used Zybooks, an online book application that made the class be able to be taken asynchronously. In contrast, Statistical Learning has no online book to use, purely class discussion. Instead of doing syllabus day, we delved right into a thorough review of Linear Algebra that was more call and response than a stratified lecture. While the class size is much smaller for the statistics department, I can already see the difference between the details of which the content will focus on. Where Intro to Machine Learning remained on the simple python application of machine learning, Statistical Learning will offer much more of the mathematical and statistical intricacies that allow machine learning to exist. Intro to Machine Learning did not even require statistics courses to have been taken before taking the course.

Machine learning is a vast field with many different types of models that have differing applications depending on the types of data that they are applied to. Binary data is analyzed with a different model or method compared to data such as the price of a good or service. The benefits are vast. Machine Learning can recognize patterns within the data, and handle vast quantities of data and prediction used in many biological fields since they deal with complex structures that cannot be easily quantifiable without the processing power of a computer.